# 一、kafka 初识

## kafka介绍

Kafka是 **Linkedin**开源的**分布式**消息系统,目前归属于Apache顶级项目，Kafka主要特点是基于**Pull**的模式来处理消息消费,追求高吞吐量,一开始的目的就是用于**日志收集和传输**。

**0.8版本开始支持复制**,不支持事务,对消息的重复、丢失、错误没有严格要求。

适合产生大量数据的互联网服务的数据收集业务。

Kafka有哪些特点

1. 具有分布式的特性，支持消息分区（partition）的概念，kafka非常核心的一个概念就是partition，一个topic下面可以有很多个partition，partition和consumer是要一一对应的，比如只有四个partition，却有十几个consumer，那其实很多consumer是浪费的。
2. 跨平台：支持不同语言的客户端。如：java、php、python
3. 高实时性：数据支持实时的处理和离线处理
4. 消息堆积能力强（上亿级别）：即使kafka数据堆积了上亿几十亿的数据，只要 你的存储是ok的，并不会影响你kafka的性能
5. 伸缩性强：支持水平扩展

Kafka 高性能的原因

1. 顺序写：顺序写盘，可以提高磁盘的利用率。比如consumer通过offset顺序地去消费消息队列中的数据，而不删除已经消费过的数据，从而避免磁盘的随机写。其实业界的主流MQ，如RocketMQ，也是借鉴了Kafka的诸多特性，假如我们要做一个MQ，那怎么去设计MQ的存储呢？和显然，要做到顺序写，每次生产者把消息发送到了MQ的broker，存储到磁盘某个点时，一定要记录一个位置，这个位置就是**offset**，这个offset肯定会被consumer去消费 ，它消费的时候一定会记录一下当前消费的位置在哪，也就是要记录一下消费的offset，然后会基于这个offset继续去找下个offset，再去消费，只有这样才能充分地利用磁盘利用率，这才是顺序写——一个一个地写，而不是随机写—— ，如果消费完了这个消息，把这个消息从这个文件中地某个点删掉，那么整个文件地offset就会变化，即会产生一个偏移，**所以**一般mq的设计都不允许删除消息。

   思考：阿里云上的消息中间件为什么支持删除某一条消息，是怎么做到的？

   肯定不是把offset对应的消息删除了，而是做了一层转储，去打标记做的，不是物理删除而是逻辑 删除。

2. Page Cache 空中接力：廉价的服务器上都可以支持单机每秒100k条吞吐量

3. 高效读写：1 2实现

4. 后台异步、主动flush

5. 预读策略，IO调度

6. 零拷贝

   在Linux kernel2.2 之后出现了一种叫做"零拷贝(zero-copy)"系统调用机制，就是跳过“用户缓冲区”的拷贝，建立一个磁盘空间和内存的直接映射，数据不再复制到“用户态缓冲区”

   传统的一个进程将磁盘中的数据发送到另一个应用程序：

   ![1588411886896](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\1588411886896.png)

   有了零拷贝

   ![1588411957706](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\1588411957706.png)

   

   分区

   kafka中的topic中的内容可以被分为多分partition存在,每个partition又分为多个段segment,所以每次操作都是针对一小部分做操作，很轻便，并且增加`并行操作`的能力
    

   

   ![img](https:////upload-images.jianshu.io/upload_images/5328368-67988a3830f07730.png?imageMogr2/auto-orient/strip|imageView2/2/w/710/format/webp)

   

   

   

## Kafka总体架构

![1588412041029](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\1588412041029.png)

我们可以看到Kafka整个集群里面仅仅包含了Broker，zookeeper两个组件。

Broker是整个Kafka集群的核心引擎，负责消息的存储转发，并对外提供服务。我们可以看到，Kafka集群可以非常简单的通过增删Broker，实现整个集群的扩缩容。Kafka对外提供服务的基本单位是Topic，那么实现Topic级别的平行扩展能力，也就实现了应用级的平行扩展能力。为了实现应用级的平行扩展能力，Kafka采用了对Topic进行分区的做法，通过对Topic进行分区让不同的分区落在不同的Broker上，从而利用到更多Broker的能力，最终实现了应用级的水平扩展。

Zookeeper则在整个集群中则主要负责存储一些配置信息、Broker信息、Topic信息等等元数据，并且承担了一部分协调选主的功能，可以将其理解为Kafka集群的配置管理中心。讲到这里，大家会觉得在Kafka集群中，可以简单的通过Broker动态的增删实现集群扩缩容，但在整个集群中却仅仅存在一个Zookeeper，那么Zookeeper会不会成为整个集群的瓶颈点，从而制约了整个集群的平行扩展能力？的确，在Kafka一些较老版本，Kafka的生产者及消费者都需要与Zookeeper进行通信交互，进行元数据拉取、消费分组协调、以及消费分组offset提交与保存等等。这样造成的一个问题，就是所有的客户端都要直接与ZooKeeper进行通讯交互，对其造成了非常大的压力，影响了系统的稳定性，最终影响整Kafka集群的平行扩展能力。但从0.9(含)版本之后，Kafka团队对整个Kafka进行了优化中，通过增加了一些协议，并且增加了协调模块。当前Kafka已经做到了客户端的生产及消费不需要与Zookeeper进行任何通讯交互，故Zookeeper当前仅仅充当了配置管理中心，压力非常的小，不会成为集群的瓶颈点进而制约集群的水平扩展能力。

大家也可以看到生产者及消费者是直接与Broker进行交互实现生产消费功能，Kafka在设计上并未采用传统系统中通过增加一层代理实现系统的平行扩展能力。Kafka在设计中通过内部路由协议，实现了生产者与消费者可以直接与Broker进行路由协商，从而实现了客户端直接与Broker进行生产消费，而不需要借助第三方代理。无代理的方式不仅会减少整个数据链路的长度，降低延迟，也可以提高整个系统的稳定性，而且也会节省大量的成本。

总结下Kafka的总体架构体现了如下几个主要的优势。其一，Kafka集群可以通过增删Broker实集群级的水平扩展。其二，通过对Topic进行分区，实现了应用级别的无限平行扩展能。其三，通过优良通讯协议，实现了生产系统直接与后端的Broker进行通讯，节省了代理，不仅减少了数据链路长度降低了延迟，而且极大的降低了成本。

至此，我想大家对Kafka已经有一个较为宏观了解。我们知道系统总体架构，决定了整个系统的能力上限。但系统中关键组件的性能，则是决定了相同能力下集群中服务器数量。服务器数量的增加，不仅仅会增加成本，而且会带来更多的运维压力及影响系统的稳定性。所以下面我将会介绍下Kafka核心引擎Broker的系统架构。

## Broker架构

我们可以看Broker是一个典型的Reactor模型，其主要包含一个网络线程池，负责处理网络请求进行网络的收发以及打包解包，然后把请求通过请求队列推送给核心处理模块，由其负责真正的业务逻辑处理（Kafka会把所有消息落地存储，故主要是些文件I/0操作）。我们可以看到kafka采用多线程方式，可以充分利用现代系统的多核优势。其次，其采用队列方式实现了网络处理模块及核心处理模块的异步解耦，实现了网络处理和文件I/O并行处理，极大的提高了整个系统的效率。

讲到这里，大家对Kafka架构已经有一个宏观的理解。上面我们也提到，Kafka会把所有的消息都落地存储。那么为什么Kafka并未像传统的[消息队列](https://cloud.tencent.com/product/cmq?from=10680)那样非常惧怕磁盘，劲量缓存而不触碰磁盘？Kafka为什么选择了将所有消息都落地存储？下面我将通过讲解其存储组织方式及存储格式，为大家进行一一揭秘。

## 存储的组织方式

这个就是当前Kafka的存储组织方式，我们可以看到Topic，其实只是逻辑概念，并不对应任何物理实体，为了实现Topic的水平扩展，Kafka会对其进行分区。Partition则以目录形式进行展现，同时Partition中具体的数据还未进行分片存储。这样在生产时，就能快速的找到最新的分配直接追加到文件末尾，可以看到Kafka在生产中充分利用了磁盘的顺序写，极大的提高了生产的吞吐能力。同时进行分片存储，还有一个好处就是我们可以非常方便的通过删除老的分片实现过期消息的删除。同时为了方便消费，Kafka在分片的命名上也采用了一定的技巧，分片的命名采用了其包含的第一条消息的offset进行格式化这样，在消费数据时，可以非常方便的通过二分查找定位到消息所在的文件分片。同时为了实现分片内快速定位，Kafka也会对每个数据分片建立两个稀疏索引文件，通过索引文件，采用二分查找可以非常快速的定位了指定消息在数据分片中的位置，进而进行消费。通过讲解我们可以看到Kafka的整个生产消费其实都是顺序读写，充分利用了磁盘顺序读写能力。其次，Kafka的消费，采用了二级二分查找，其查找性能仅仅依赖一个分片的索引大小，不会受整个系统数据量的影响。