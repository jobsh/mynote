# 分布式限流

## 一、分布式限流介绍

刚才和同学们打了个亲切的照面，接下来我们就要正式开始分布式限流的课程了。作为分布式大章节的收官之作，我把这一章课程节奏设置的比较缓和，让大家可以回顾和沉淀前面学到的分布式知识，用一种轻松的心态迎接下一个大章节-微服务架构设计与落地。

说到“限流”这个词，我想同学们在实际生活中肯定经历过“被限流”的情况，只是大家浑然不觉，接下来就让我们回顾下那些深藏不漏的限流手段。

### 那些年被欺骗的感情

春运，一项全人类历史上最大规模的迁移活动，抢火车票一直是每年跨年以后的热点话题。提起这个沉重的话题，我们不得不说起12306某个由5位数字组成的网站。大家每年都要通过这个网站购买火车票，这个系统在春运期间所承受的访问压力那是相当的大，毕竟不是所有人都会参加双11，但是大家过年总是要回老家的。

话说降低系统压力最有效的方式就是减少访问流量，说白了就是把用户拒之门外。比如说，我可以给用户一句“服务正忙”的提示，将用户请求丢弃不管。但是这种事儿又不好光明正大的做，毕竟全国人民都知道我这网站花了好几个亿的成本。那怎么样才能做到不声不响把用户流量限制住呢？答案在这里：
![图片描述](https://climg.mukewang.com/5e0f159509ccc24614041096.png)

没错，就是坑死你没商量的**验证码**！

同学们肯定发现了这样一种情况，在春运抢票的时候，当你面对这么一堆验证码图片，不管你怎么选，即使你用毕生所学选出了正确答案，提交后依然都会被告知你选错了。要么就是让你面对一堆鬼都看不出是什么东西的图片。不要怀疑自己的智商，其实，这就是网站的一种别样的限流措施。在拷问用户智商的同时，通过这种“故意”刁难的手段，光明正大地限制访问流量，从而大幅降低系统的访问压力，真不得不敬佩产品经理的智(良)慧(心)。

### 野史君爆料

某年某月某日，阿里集团一众工程师接到了一个大佬的神秘通知，告知他们要去做一项“不能说的任务”。随后，这波研发人员就像人间蒸发了一样，闭关消失了几个月。我们都以为他们去北国边疆造原子弹的时候，英雄们凯旋归来。随后，某个5位数字的网站改头换面悄然上线。这是巧合吗？我可什么都没说。不过话说回来，虽然改版后网站性能没感觉有多大提升，但是图片验证码的难度却大幅提高，工程师们以曲线救国的方式缓解了系统压力瓶颈。

### 分布式限流的几种维度

通过前面的例子，再加上大家过往的经验，不难理解“限流”的含义，对一般的限流场景来说它具有两个维度的信息：

**时间** 限流基于某段时间范围或者某个时间点，也就是我们常说的“时间窗口”，比如对每分钟、每秒钟的时间窗口做限定
**资源** 基于可用资源的限制，比如设定最大访问次数，或最高可用连接数

上面两个维度结合起来看，限流就是在某个时间窗口对资源访问做限制，比如设定每秒最多100个访问请求。但在真正的场景里，我们不止设置一种限流规则，而是会设置多个限流规则共同作用，主要的几种限流规则如下：

![图片描述](https://climg.mukewang.com/5e0f15a8097b023f27401174.png)

#### QPS和连接数控制

针对上图中的连接数和QPS(query per second)限流来说，我们可以设定IP维度的限流，也可以设置基于单个服务器的限流。在真实环境中通常会设置多个维度的限流规则，比如设定同一个IP每秒访问频率小于10，连接数小于5，再设定每台机器QPS最高1000，连接数最大保持200。更进一步，我们可以把某个服务器组或整个机房的服务器当做一个整体，设置更high-level的限流规则，这些所有限流规则都会共同作用于流量控制。

在稍后的小节里，我们的实践Demo部分将主要围绕在QPS和连接数控制的限流规则。

#### 传输速率

对于“传输速率”大家都不会陌生，比如资源的下载速度。有的网站在这方面的限流逻辑做的更细致，比如普通注册用户下载速度为100k/s，购买会员后是10M/s，这背后就是基于用户组或者用户标签的限流逻辑。

在稍后的小节我们会给大家展示如何在Nginx中限制传输速度。

#### 黑白名单

黑白名单是各个大型企业应用里很常见的限流和放行手段，而且黑白名单往往是动态变化的。举个例子，如果某个IP在一段时间的访问次数过于频繁，被系统识别为机器人用户或流量攻击，那么这个IP就会被加入到黑名单，从而限制其对系统资源的访问，这就是我们俗称的“封IP”。

我们平时见到的爬虫程序，比如说爬知乎上的美女图片，或者爬券商系统的股票分时信息，这类爬虫程序都必须实现更换IP的功能，以防被加入黑名单。有时我们还会发现公司的网络无法访问12306这类大型公共网站，这也是因为某些公司的出网IP是同一个地址，因此在访问量过高的情况下，这个IP地址就被对方系统识别，进而被添加到了黑名单。使用家庭宽带的同学们应该知道，大部分网络运营商都会将用户分配到不同出网IP段，或者时不时动态更换用户的IP地址。

白名单就更好理解了，相当于御赐金牌在身，可以自由穿梭在各种限流规则里，畅行无阻。比如某些电商公司会将超大卖家的账号加入白名单，因为这类卖家往往有自己的一套运维系统，需要对接公司的IT系统做大量的商品发布、补货等等操作。

#### 分布式环境

所谓的分布式限流，其实道理很简单，一句话就可以解释清楚。分布式区别于单机限流的场景，它把整个分布式环境中所有服务器当做一个整体来考量。比如说针对IP的限流，我们限制了1个IP每秒最多10个访问，不管来自这个IP的请求落在了哪台机器上，只要是访问了集群中的服务节点，那么都会受到限流规则的制约。

从上面的例子不难看出，我们必须将限流信息保存在一个“中心化”的组件上，这样它就可以获取到集群中所有机器的访问状态，目前有两个比较主流的限流方案：

- **网关层限流** 将限流规则应用在所有流量的入口处
- **中间件限流** 将限流信息存储在分布式环境中某个中间件里（比如Redis缓存），每个组件都可以从这里获取到当前时刻的流量统计，从而决定是拒绝服务还是放行流量

## 二、常见的分布式限流方案

前面我们了解了什么是分布式限流，这一节我们就来细数一下分布式限流都有哪些常见方案。

话说条条大道通罗马，实现分布式限流的方案之多，两只手加起来都数不过来。这一节我们就挑选几个比较有代表性的方案让大家先睹为快，后面我将选择其中三个主流方案，同大家一道手把手练习。

P.S. 选择恐惧症的同学不要担心，稍后的章节会给出推荐方案。

### Guava乱入

**半仙老师**：来者何人！报上名来！
**Guava**：我是Google出品的客户端限流工具，我的特点是。。。
**半仙老师**：打住，你一客户端组件，和分布式有什么关系
**Guava**：没半毛钱关系，但是我作为使用起来最简单的客户端限流组件，可谓老少皆宜，就给个上台机会呗
**半仙老师**：好吧好吧，长话短说，麻溜的

说起Guava大家一定不陌生，它是Google出品的一款工具包（com.google.guava），我们经常用它做一些集合操作比如`Lists.newArrayList()`，它最早源于2007年的"Google Collections Library"项目。Guava不甘于将自己平凡的一生都耗费在Collections上面，于是乎它开始了转型，慢慢扩展了自己在Java领域的影响力，从反射工具、函数式编程、安全验证、数学运算等等方面，都提供了响应的工具包。

在限流这个领域中，Guava也贡献了一份绵薄之力，在其多线程模块下提供了以RateLimiter为首的几个限流支持类。我们前面提到了，Guava是一个客户端组件，也就是说它的作用范围仅限于“当前”这台服务器，不能对集群以内的其他服务器施加流量控制。

![图片描述](https://climg.mukewang.com/5e0f1651099530a430000894.png)

打个比方，目前我有2台服务器[Server 1，Server 2]，这两台服务器都部署了一个登陆服务，假如我希望对这两台机器的流量进行控制，比如将两台机器的访问量总和控制在每秒20以内，如果用Guava来做，只能独立控制每台机器的访问量<=10。

尽管Guava不是面对分布式系统的解决方案，但是其作为一个简单轻量级的客户端限流组件，非常适合来讲解限流算法，稍后的章节我们将使用Guava做一个热身，让大家对限流的算法理论有了大致的了解以后，再学习其他的分布式限流方案。

### 网关层限流

> 剑阁峥嵘而崔嵬，一夫当关，万夫莫开
> –《蜀道难》李白

在整个分布式系统中，如果有这么一个“一夫当关，万夫莫开”的角色，非网关层莫属。服务网关，作为整个分布式链路中的第一道关卡，承接了所有用户来访请求.

#### 网关层限流的架构考量

漏斗是个好东西，不仅可以用来打香油，还可以应用在很多系统设计的领域，我们将系统流量的分布层次抽象成一个简单的漏斗模型来看

![图片描述](https://climg.mukewang.com/5e0f165e095962b422641444.png)

上面是一个最普通的流量模型，从上到下的路径依次是：

1. 用户流量从网关层转发到后台服务
2. 后台服务承接流量，调用缓存获取数据
3. 缓存中无数据，则访问数据库

为什么说它是一个漏斗模型，因为流量自上而下是逐层递减的，在网关层聚集了最多最密集的用户访问请求，其次是后台服务。然后经过后台服务的验证逻辑之后，刷掉了一部分错误请求，剩下的请求落在缓存上，如果缓存中没有数据才会请求漏斗最下方的数据库，因此数据库层面请求数量最小（相比较其他组件来说数据库往往是并发量能力最差的一环，阿里系的MySQL即便经过了大量改造，单机并发量也无法和Redis、Kafka之类的组件相比）

如果在上面这个漏斗模型中做流量限制，大家觉得在哪个环节最合适？五四三二一，揭晓答案–网关层，它首当其冲对不对？因为它是整个访问链路的源头，是所有流量途径的第一站。目前主流的网关层有以软件为代表的**Nginx**，还有Spring Cloud中的**Gateway**和**Zuul**这类网关层组件，也有以硬件+软件为代表的F5（F5价钱贵到你怀疑人生）

### Nginx限流

同学们在前面已经系统的学习了Nginx的知识，所以我们在这章将以Nginx为例，手把手教大家如何利用Nginx实现网关层限流。在后面的微服务章节我们将涉及到Spring Cloud中的Gateway组件的网关层限流。

**我是剧透**：在下面的内容中我们将介绍Nginx里的几种核心限流模式：

1. 基于IP地址和基于服务器的访问请求限流
2. 并发量（连接数）限流
3. 下行带宽速率限制

### 中间件限流

开发团队的年轻人们都是很有控制欲的，网关层限流对他们来说貌似有点不那么受控，毕竟不像改个程序代码那么简单，搞不好还要求爷爷告奶奶去让运维团队或者NetOpts团队去操作。我们有没有一个解决方案，将限流下沉到业务层来，让开发团队可以自行控制？我们来思考一下如何在分布式环境中引入服务层限流。

对于分布式环境来说，无非是需要一个类似中心节点的地方存储限流数据。打个比方，如果我希望控制接口的访问速率为每秒100个请求，那么我就需要将当前1s内已经接收到的请求的数量保存在某个地方，并且可以让集群环境中所有节点都能访问。那我们可以用什么技术来存储这个临时数据呢？这个场景天然适合我们的中间件大显神威！而且还得需要支持超高并发的中间件，谁能堪此重任？

一并中间件这下起劲儿了，纷纷表示“选我选我选我”。数据库行不行？不行，并发量不够。Message Queue行不行？好像MQ的运作模式不太适合这个场景，而且并发量也就差强人意。Kafka行不行，嗯，并发量杠杠的，是个Option。那Redis呢？OMG，憋说话就你了！理由这就给足你！
![图片描述](https://climg.mukewang.com/5e0f166c09290e3c07000285.png)

Redis简直就是为服务端限流量身打造的利器。利用Redis过期时间特性，我们可以轻松设置限流的时间跨度（比如每秒10个请求，或者每10秒10个请求）。同时Redis还有一个特殊技能–脚本编程，我们可以将限流逻辑编写成一段脚本植入到Redis中，这样就将限流的重任从服务层完全剥离出来，同时Redis强大的并发量特性以及高可用集群架构也可以很好的支持庞大集群的限流访问。

至于我们说到的Redis执行脚本的功能，可能很多同学用了多年Redis，至今还不知道有这么个隐藏技能。这回我就不剧透了，保留一点神秘感，在本章最后将介绍一种可以和Redis完美搭配的脚本语言，并且手把手教大家实现基于Redis的限流。

### 限流组件

除了上面介绍的几种方式以外，目前也有一些开源组件提供了类似的功能，比如Sentinel就是一个不错的选择。Sentinel是阿里出品的开源组件，并且包含在了Spring Cloud Alibaba组件库中，可以为Cloud服务在下一个“微服务架构设计与落地”的大章节中，我们将详细介绍Sentinel在分布式限流中的应用。

### 从架构维度考虑限流设计

在真实的大型项目里，不会只使用一种限流手段，往往是几种方式互相搭配使用，让限流策略有一种层次感，达到资源的最大使用率。在这个过程中，限流策略的设计也可以参考前面提到的漏斗模型，上宽下紧，漏斗不同部位的限流方案设计要尽量关注当前组件的高可用。以我参与的实际项目为例，比如说我们研发了一个商品详情页的接口，通过手机淘宝导流，app端的访问请求首先会经过阿里的mtop网关，在网关层我们的限流会做的比较宽松，等到请求通过网关抵达后台的商品详情页服务之后，再利用一系列的中间件+限流组件，对服务进行更加细致的限流控制（这里面还会包含熔断降级等一系列复杂的异常处理，在微服务的章节中我们再深入学习，大家可以期待一下）

## 三、常见的限流算法

### 令牌桶算法

Token Bucket令牌桶算法是目前应用最为广泛的限流算法，顾名思义，它有以下两个关键角色：

1. **令牌** 获取到令牌的Request才会被处理，其他Requests要么排队要么被直接丢弃
2. **桶** 用来装令牌的地方，所有Request都从这个桶里面获取令牌

了解了这两个角色之后，让我们来看一下令牌桶算法的图示：

![图片描述](https://climg.mukewang.com/5e0f176d09e1a32330281388.png)

下面我们分别从令牌生成和令牌获取两个流程来解读令牌桶算法：

#### 令牌生成

这个流程涉及到令牌生成器和令牌桶，前面我们提到过令牌桶是一个装令牌的地方，既然是个桶那么必然有一个容量，也就是说令牌桶所能容纳的令牌数量是一个固定的数值。

对于令牌生成器来说，它会根据一个预定的速率向桶中添加令牌，比如我们可以配置让它以每秒100个请求的速率发放令牌，或者每分钟50个。注意这里的发放速度是匀速，也就是说这50个令牌并非是在每个时间窗口刚开始的时候一次性发放，而是会在这个时间窗口内匀速发放。

在令牌发放器就是一个水龙头，假如在下面接水的桶子满了，那么自然这个水（令牌）就流到了外面。在令牌发放过程中也一样，令牌桶的容量是有限的，如果当前已经放满了额定容量的令牌，那么新来的令牌就会被丢弃掉。

**思考题**：大家知道为什么要匀速发放吗？同学们先自己思考一下。在这一章的最后一个小节里，我们再来探讨匀速限流和非匀速限流的区别，以及这里面可能会踩到的坑。

#### 令牌获取

每个访问请求到来后，必须获取到一个令牌才能执行后面的逻辑。假如令牌的数量少，而访问请求较多的情况下，一部分请求自然无法获取到令牌，那么这个时候我们可以设置一个“缓冲队列”来暂存这些多余的令牌。

缓冲队列其实是一个可选的选项，并不是所有应用了令牌桶算法的程序都会实现队列。当有缓存队列存在的情况下，那些暂时没有获取到令牌的请求将被放到这个队列中排队，直到新的令牌产生后，再从队列头部拿出一个请求来匹配令牌。

当队列已满的情况下，这部分访问请求将被丢弃。在实际应用中我们还可以给这个队列加一系列的特效，比如设置队列中请求的存活时间，或者将队列改造为PriorityQueue，根据某种优先级排序，而不是先进先出。算法是死的，人是活的，先进的生产力来自于不断的创造，在技术领域尤其如此。

### 漏桶算法

Leaky Bucket。瞧见没，又是个桶，限流算法是跟桶杠上了，那么漏桶和令牌桶有什么不同呢？我们来看图说话：

![图片描述](https://climg.mukewang.com/5e0f177b09c240dc25841544.png)

漏桶算法的前半段和令牌桶类似，但是操作的对象不同，令牌桶是将令牌放入桶里，而漏桶是将访问请求的数据包放到桶里。同样的是，如果桶满了，那么后面新来的数据包将被丢弃。

漏桶算法的后半程是有鲜明特色的，它永远只会以一个恒定的速率将数据包从桶内流出。打个比方，如果我设置了漏桶可以存放100个数据包，然后流出速度是1s一个，那么不管数据包以什么速率流入桶里，也不管桶里有多少数据包，漏桶能保证这些数据包永远以1s一个的恒定速度被处理。

### 漏桶 vs 令牌桶的区别

根据它们各自的特点不难看出来，这两种算法都有一个“恒定”的速率和“不定”的速率。令牌桶是以恒定速率创建令牌，但是访问请求获取令牌的速率“不定”，反正有多少令牌发多少，令牌没了就干等。而漏桶是以“恒定”的速率处理请求，但是这些请求流入桶的速率是“不定”的。

从这两个特点来说，漏桶的天然特性决定了它不会发生突发流量，就算每秒1000个请求到来，那么它对后台服务输出的访问速率永远恒定。而令牌桶则不同，其特性可以“预存”一定量的令牌，因此在应对突发流量的时候可以在短时间消耗所有令牌，其突发流量处理效率会比漏桶高，但是导向后台系统的压力也会相应增多。

### 滑动窗口

Rolling Window，穿上你的滑板鞋，跟我一起摇摆。
![图片描述](https://climg.mukewang.com/5e0f17870983b50a33121060.png)

上图中黑色的大框就是时间窗口，我们设定窗口时间为5秒，它会随着时间推移向后滑动。我们将窗口内的时间划分为五个小格子，每个格子代表1秒钟，同时这个格子还包含一个计数器，用来计算在当前时间内访问的请求数量。那么这个时间窗口内的总访问量就是所有格子计数器累加后的数值。

比如说，我们在每一秒内有5个用户访问，第5秒内有10个用户访问，那么在0到5秒这个时间窗口内访问量就是15。如果我们的接口设置了时间窗口内访问上限是20，那么当时间到第六秒的时候，这个时间窗口内的计数总和就变成了10，因为1秒的格子已经退出了时间窗口，因此在第六秒内可以接收的访问量就是20-10=10个。

滑动窗口其实也是一种计算器算法，它有一个显著特点，当时间窗口的跨度越长时，限流效果就越平滑。打个比方，如果当前时间窗口只有两秒，而访问请求全部集中在第一秒的时候，当时间向后滑动一秒后，当前窗口的计数量将发生较大的变化，拉长时间窗口可以降低这种情况的发生概率

## 四、使用Guava的RateLimiter进行客户端的限流（非分布式限流）

### 初时Guava的RateLimiter

Guava的 `RateLimiter`提供了令牌桶算法实现。Guava的**RateLimiter有两种限流模式**，一种为稳定模式(**SmoothBursty**:令牌生成速度恒定)，一种为渐进模式(**SmoothWarmingUp**:令牌生成速度缓慢提升直到维持在一个稳定值)，两种模式实现思路类似，主要区别在等待时间的计算上，通过RateLimiter获取令牌也分为两种方式：非阻塞式和阻塞式。

![1596698683000](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\1596698683000.png)

`RateLimiter`的类图如上所示，其中 `RateLimiter`是入口类，它提供了两套工厂方法来创建出两个子类。这很符合《Effective Java》中的用静态工厂方法代替构造函数的建议，毕竟该书的作者也正是Guava库的主要维护者，二者配合"食用"更佳。

### 非阻塞式

非阻塞式每一次的请求，不管成功还是失败都会**立刻返回请求的结果**

```java
package com.imooc.springcloud;

import com.google.common.util.concurrent.RateLimiter;
import lombok.extern.slf4j.Slf4j;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

/**
 * @desc: 使用guava演示非阻塞式的限流
 * @author: Mr.Han
 */
@RestController
@Slf4j
public class RateLimiterController {

    // 每两秒产生一个放行许可证（令牌）
    RateLimiter rateLimiter = RateLimiter.create(2);

    @GetMapping("tryAcquire")
    public String tryAcquire(int count){
        // 尝试获取通行许可证
        if (rateLimiter.tryAcquire(count)) {
            log.info("success," + "rate is {}", rateLimiter.getRate());
            return "success";
        } else {
            log.info("fail," + "rate is {}", rateLimiter.getRate());
            return "fail";
        }
    }


}
```

如果tryAcquire中传入的是2，也就是每次请求要消耗两个通行证，也就是每隔一秒可以成功请求一次，在一秒内无法请求成果两次，运行结果如图所示：

![image-20200805184237053](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200805184237053.png)

从运行结果中可以佐证上面的猜测，但是我们发现了一个奇怪的现象：在一开始的1两个请求，他们都是在一秒内发起的，竟然同时成功了，这是为什么呢？具体原因在后面的预热会详细谈到。

有的小伙伴可能还会有这样的疑惑？如果传入的tryAcquire参数是大于2的呢？是直接拒绝吗？

答案是否定的，RateLimiter是运行请求成功的，加入tryAcquire的实参是4，那么我们会允许这一次请求，但是缺少两个通行证怎么办呢？RateLimiter会采取欠账的方式允许请求的通过，欠的通行证需要下一个请求来偿还。

上面的案例，请求来的时候，没有规定数量的通信证，就直接失败了，可是如果我不想立刻失败，我想在一定的时间内重试，如果在这有限时间内，存够了通行证在放行，这种需求怎么实现呢？这就用到了带参数的tryAcquire

```java
@GetMapping("tryAcquireWithTime")
public String tryAcquireWithTime(int count, Long timeout){
    // 尝试获取通行许可证,在2s内可以重试，如果获得了就请求成功，如果没有2秒内肯定无法产出想要的同行整，则快速失败
    if (rateLimiter.tryAcquire(count, timeout, TimeUnit.SECONDS)) {
        log.info("success," + "rate is {}", rateLimiter.getRate());
        return "success";
    } else {
        log.info("fail," + "rate is {}", rateLimiter.getRate());
        return "fail";
    }
}
```

通过postman可以每秒发送一个请求

请求1不带timeout：http://localhost:10086/tryAcquire?count=4

请求2带有timeout：http://localhost:10086/tryAcquireWithTime?count=4&timeout=2

结果对比：

请求一的结果：成功一次失败一次，请求成功后只有过两秒才会再次请求成功

![image-20200805191344327](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200805191344327.png)

请求2：虽然我们设置的是每秒发送一次请求，但是我们会发现真正过来的请求是每两秒一次，这就可以说明在没有拿到令牌的时候，请求会在timeout时间内阻塞，下一次请求如果在阻塞时间内，则无法过来（强制用户这段时间无法再次发起请求），直到在阻塞时间内前一个请求拿到应拿的令牌数量，才会有下一个请求的到来，所以每次请求都是成功的

![image-20200805191531160](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200805191531160.png)

注意：每一次的请求rateLimiter会判到：在timeout时间内你是否可以等到我生产出你所需要的令牌数量，如果不能，我会直接返回失败。这是一种快速失败的机制，目的是提升性能，不至于一直阻塞。

### 阻塞式

使用acquire方法，获取不到令牌就阻塞。

```java
// 同步阻塞限流
@GetMapping("/acquire")
public String acquire(Integer count) {
    rateLimiter.acquire(count);
    log.info("success, rate is {}", rateLimiter.getRate());
    return "success";
}
```

### RateLimiter应用场景

用在**单机资源比较敏感**的服务器上，它本身不是一种分布式限流方案，可以和分布式限流配合使用。

### Guava RateLimiter预热模型

上一节我们了解了Guava组件是如何提供客户端限流功能的，这一节我们借Guava来讲一个和限流有关的小技巧 - 「流量预热」

### 什么是流量预热

我们都知道在做运动之前先得来几组拉伸之类的动作，给身体做个热身，让我们的身体平滑过渡到后面的剧烈运动中。流量预热也是一样的道理，对限流组件来说，流量预热就类似于一种热身运动，它可以动态调整令牌发放速度，让流量变化更加平滑。

我们来举一个例子：某个接口设定了100个Request每秒的限流标准，同时使用令牌桶算法做限流。假如当前时间窗口内都没有Request过来，那么令牌桶中会装满100个令牌。如果在下一秒突然涌入100个请求，这些请求会迅速消耗令牌，对服务的瞬时冲击会比较大。因此我们需要一种类似“热身运动”的缓冲机制，根据桶内的令牌数量动态控制令牌的发放速率，让忙时流量和闲时流量可以互相平滑过渡。

### 流量预热的做法

我们以Guava中的RateLimiter为例，看看流量预热在RateLimiter中是如何运作的，我们用下面的状态转换图来展示整个过程：

![图片描述](https://climg.mukewang.com/5e0f181c09040c5330901686.png)

横坐标是令牌桶的当前容量，纵坐标是令牌发放速率，我们先从横坐标来分析

#### 横坐标

下面两种场景会导致横坐标的变化：

1. **闲时流量** 流量较小或者压根没流量的时候，横坐标会逐渐向右移动，表示令牌桶中令牌数量增多
2. **忙时流量** 当访问流量增大的时候，横坐标向左移动，令牌桶中令牌数量变少

横轴有两个重要的坐标，一个是最右侧的“令牌桶最大容量”，这个不难理解。还有一个是Half容量，它是一个关键节点，会影响令牌发放速率。

#### 纵坐标

纵坐标表示令牌的发放速率，这里有3个标线，分别是稳定时间间隔，2倍间隔，3倍间隔。

这里间隔的意思就是隔多长时间发放一个令牌，而所谓稳定间隔就是一个基准时间间隔。假如我们设置了每秒10个令牌的限流规则，那么稳定间隔也就是1s/10=0.1秒，也就是说每隔0.1秒发一个令牌。相应的，3倍间隔的数值是用稳定间隔乘以系数3，比如上面这个例子中3倍间隔就是0.3秒。

#### 运作模式

了解了横坐标和纵坐标的含义之后，让我们来试着理解预热模型的用例。继续沿用上面10r/s的限流设置，稳定间隔=0.1s，3x间隔是0.3s。

我们先考虑闲时到忙时的流量转变，假定当前我们处于闲时流量阶段，没几个访问请求，这时令牌桶是满的。接着在下一秒突然涌入了10个请求，这些请求开始消耗令牌桶中的令牌。在初始阶段，令牌的放行速度比较慢，在第一个令牌被消耗以后，后面的请求要经过3x时间间隔也就是0.3s才会获取第二块令牌。随着令牌桶中令牌数量被逐渐消耗，当令牌存量下降到最大容量一半的时候（Half位置），令牌放行的速率也会提升，以稳定间隔0.1s发放令牌。

反过来也一样，在流量从忙时转变为闲时的过程中，令牌发放速率是由快到慢逐渐变化。起始阶段的令牌放行间隔是0.1s，随着令牌桶内令牌逐渐增多，当令牌的存量积累到最大容量的一半后，放行令牌的时间间隔进一步增大为0.3s。

RateLimiter正是通过这种方式来控制令牌发放的时间间隔，从而使流量的变化更加平滑。

#### 核心代码

理解了预热模型的运作流程之后，我们来看一下具体代码是如何实现的。

实现流量预热的类是SmoothWarmingUp，它是SmoothRateLimiter的一个内部类，我们重点关注一个doSetRate方法，它是计算横纵坐标系关键节点的方法，先来看一下SmoothRateLimiter这个父类中定义的方法

```java
// permitsPerSecond表示每秒可以发放的令牌数量
@Override
final void doSetRate(double permitsPerSecond, long nowMicros) {
  resync(nowMicros);
  
  // 计算稳定间隔，使用1s除以令牌桶容量
  double stableIntervalMicros = SECONDS.toMicros(1L) / permitsPerSecond;
  this.stableIntervalMicros = stableIntervalMicros;
  
  // 调用SmoothWarmingUp类中重载的doSetRate方法
  doSetRate(permitsPerSecond, stableIntervalMicros);
}
```

父类在这里的作用主要是计算出了稳定时间间隔（使用1s / 每秒放行数量的公式来计算得出），然后预热时间、三倍间隔等是在子类的doSetRate方法中实现的。

接下来我们看子类SmoothWarmingUp中的doSetRate做了什么

```java
@Override
void doSetRate(double permitsPerSecond, double stableIntervalMicros) {
  	double oldMaxPermits = maxPermits;
  	
	// maxPermits表示令牌桶内最大容量，它由我们设置的预热时间除以稳定间隔获得
	// 打个比方，如果stableIntervalMicros=0.1s，而我们设置的预热时间是2s
	// 那么这时候maxPermits就是2除以0.1=20
  	maxPermits = warmupPeriodMicros / stableIntervalMicros;
  	
  	// 这句不用解释了吧，halfPermits是最大容量的一半
  	halfPermits = maxPermits / 2.0;
  
  	// coldIntervalMicros就是我们前面写到的3倍间隔，通过稳定间隔*3计算得出
  	// 稳定间隔是0.1，3倍间隔是0.2，那么平均间隔是0.2
  	double coldIntervalMicros = stableIntervalMicros * 3.0;
  	
  	// slope的意思是斜率，也就是前面我们图中预热阶段中画出的斜线（速率从稳定间隔向3x间隔变化的斜线）
  	// 它的计算过程就是一个简单的求斜率公式
  	slope = (coldIntervalMicros - stableIntervalMicros) / halfPermits;
  	
  	// 计算目前令牌桶的令牌个数
  	if (oldMaxPermits == Double.POSITIVE_INFINITY) {
  		// 如果令牌桶最大容量是无穷大，则设置当前可用令牌数为0
  		// 说实话这段逻辑没什么用
    	storedPermits = 0.0;
  	} else {
    	storedPermits = (oldMaxPermits == 0.0)
        	? maxPermits // 初始化的状态是3x间隔
        	: storedPermits * maxPermits / oldMaxPermits;
  }
}
```

通过上面的两个函数，RateLimiter限流器就对maxPermits和slope（预热期斜率）两个变量做了初始化配置。我把关键步骤都注释在了代码里，大家理解了之后，可以尝试去阅读这个类的其他方法，弄清maxPermits和slope是如何影响令牌发放速率的。

关于guava RateLimiter：<https://zhuanlan.zhihu.com/p/60979444>

## 五、Nginx限流

Nginx官方版本限制IP的连接和并发分别有两个模块：

- **limit_req_zone** 用来限制单位时间内的请求数，即速率限制,采用的漏桶算法 "leaky bucket"。
- **limit_conn_zone** 用来限制同一时间连接数，即并发限制。

上面两种限流方式又可以基于ip（ $binary_remote_addr）和整个服务器（$server_name）进行限流

Nginx按请求速率限速模块使用的是漏桶算法，即能够强行保证请求的实时处理速度不会超过设置的阈值。 指令

> Syntax:	limit_req zone=name [burst=number] [nodelay | delay=number]; Default:	— Context:	http, server, location

```nginx
# 根据服务器级别做限流
limit_req_zone $server_name zone=serverlimit:10m rate=100r/s;

# 基于连接数的配置
limit_conn_zone $binary_remote_addr zone=perip:20m;
limit_conn_zone $server_name zone=perserver:20m;
# key ：定义限流对象，binary_remote_addr 是一种key，表示基于 remote_addr(客户端IP) 来做限流，binary_ 的目的是压缩内存占用量。
# zone：定义共享内存区来存储访问信息， one:10m 表示一个大小为10M，名字为perip的内存区域。1M能存储16000 IP地址的访问信息，10M可以存储16W IP地址访问信息。
# rate 用于设置最大访问速率，rate=10r/s 表示每秒最多处理10个请求。Nginx 实际上以毫秒为粒度来跟踪请求信息，因此 10r/s 实际上是限制：每100毫秒处理一个请求。这意味着，自上一个请求处理完后，若后续100毫秒内又有请求到达，将拒绝处理该请求。如果限制的频率低于1r/s，则可以使用r/m，如30r/m。

    server {
        server_name www.imooc-training.com;
        location /access-limit/ {
            proxy_pass http://127.0.0.1:10086/;

            # 1. 基于IP地址的限制
            # 1） 第一个参数zone=iplimit => 引用limit_req_zone中的zone变量
            # 2） 第二个参数burst=2，设置一个大小为2的缓冲区域，当大量请求到来。
            #     请求数量超过限流频率时，将其放入缓冲区域
            # 3) 第三个参数nodelay=> nodelay和burst配合使用，burst中的请求会立刻被处理，burst缓冲区满了以后，直接返回503异常，如果没有设置，则所有请求会等待排队。
            limit_req zone=iplimit burst=2 nodelay;

            # 2. 基于服务器级别的限制
            # 通常情况下，server级别的限流速率是最大的
            limit_req zone=serverlimit burst=100 nodelay;

            # 每个server最多保持100个连接
            limit_conn perserver 100;
            # 每个IP地址最多保持1个连接
            limit_conn perip 5;

            # 异常情况，返回504（默认是503）
            limit_req_status 504;
            limit_conn_status 504;
        }

        # 彩蛋
        location /download/ {
        	# 下载流量超过100m后限速
            limit_rate_after 100m;
        	# 限速为256k/s
            limit_rate 256k;
        }
    }
```

## 使用redis + lua进行分布式限流

目标：这里我们使用注解达到分布式限流

思路：

1. 定义一个限流的注解`@AccessLimit`，在方法上加上该注解就可以实现分布式限流。
2. 定义一个aop切面类，拦截使用了`@AccessLimit`的方法
3. 获取注解中的方法签名和limit限流量，传入lua脚本中
4. 使用redisTemplate执行lua脚本

### 1. 配置redis

application.properties配置：

```properties
spring.application.name=ratelimiter-test
server.port=10086

spring.redis.database=0
spring.redis.host=192.168.248.113
spring.redis.port=6379
spring.redis.password=imooc

logging.file=log/${spring.application.name}.log
```

配置redisTemplate和redisScript

```java
package com.imooc.springcloud;

import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.io.ClassPathResource;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.data.redis.core.script.DefaultRedisScript;

/**
 * Created by 半仙.
 */
@Configuration
public class RedisConfiguration {

    // 如果本地也配置了StringRedisTemplate，可能会产生冲突
    // 可以指定@Primary，或者指定加载特定的@Qualifier
    @Bean
    public RedisTemplate<String, String> redisTemplate(
            RedisConnectionFactory factory) {
        return new StringRedisTemplate(factory);
    }

    @Bean
    public DefaultRedisScript loadRedisScript() {
        DefaultRedisScript redisScript = new DefaultRedisScript();
        redisScript.setLocation(new ClassPathResource("ratelimiter.lua"));
        redisScript.setResultType(java.lang.Boolean.class);
        return redisScript;
    }

}
```

redisScript是用来封装lua的

### lua脚本

```lua
-- 获取方法签名特征
local methodKey = KEYS[1]
redis.log(redis.LOG_DEBUG, 'key is', methodKey)

-- 调用脚本传入的限流大小
local limit = tonumber(ARGV[1])

-- 获取当前流量大小
local count = tonumber(redis.call('get', methodKey) or "0")

-- 是否超出限流阈值
if count + 1 > limit then
    -- 拒绝服务访问
    return false
else
    -- 没有超过阈值
    -- 设置当前访问的数量+1
    redis.call("INCRBY", methodKey, 1)
    -- 设置过期时间
    redis.call("EXPIRE", methodKey, 10)
    -- 放行
    return true
end
```

定义限流注解：

```java
package com.imooc.springcloud.annotation;

import java.lang.annotation.*;

/**
 * Created by 半仙.
 */
@Target({ElementType.METHOD})
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface AccessLimit {

    int limit();

    // 限制的方法标识
    String methodKey() default "";

}
```

定义拦截的切面

```java
package com.imooc.springcloud.annotation;

import com.google.common.collect.Lists;
import lombok.extern.slf4j.Slf4j;
import org.aspectj.lang.JoinPoint;
import org.aspectj.lang.annotation.Aspect;
import org.aspectj.lang.annotation.Before;
import org.aspectj.lang.annotation.Pointcut;
import org.aspectj.lang.reflect.MethodSignature;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.data.redis.core.script.RedisScript;
import org.springframework.stereotype.Component;
import org.springframework.util.StringUtils;

import java.lang.reflect.Method;
import java.util.Arrays;
import java.util.stream.Collectors;

/**
 * Created by 半仙.
 */
@Slf4j
@Aspect
@Component
public class AccessLimiterAspect {

    @Autowired
    private StringRedisTemplate stringRedisTemplate;

    @Pointcut("@annotation(AccessLimit)")
    public void cut() {
        log.info("cut");
    }

    @Autowired
    private RedisScript<Boolean> rateLimitLua;

    @Before("cut()")
    public void before(JoinPoint joinPoint) {
        // 1. 获得方法签名，作为method Key
        MethodSignature signature = (MethodSignature) joinPoint.getSignature();
        Method method = signature.getMethod();

        AccessLimit annotation = method.getAnnotation(AccessLimit.class);
        if (annotation == null) {
            return;
        }

        // 获取注解中自定义的key，默认为空
        String key = annotation.methodKey();
        // 获取限制访问次数
        Integer limit = annotation.limit();

        // 如果没设置methodkey, 从调用方法签名生成自动一个key
        if (StringUtils.isEmpty(key)) {
            Class[] type = method.getParameterTypes();
            key = method.getClass() + method.getName();

            if (type != null) {
                String paramTypes = Arrays.stream(type)
                        .map(Class::getName)
                        .collect(Collectors.joining(","));
                log.info("param types: " + paramTypes);
                // 区分重载方法
                key += "#" + paramTypes;
            }
        }

        // 2. 调用Redis
        boolean acquired = stringRedisTemplate.execute(
                rateLimitLua, // Lua script的真身
                Lists.newArrayList(key), // Lua脚本中的Key列表
                limit.toString() // Lua脚本Value列表
        );

        if (!acquired) {
            log.error("your access is blocked, key={}", key);
            throw new RuntimeException("Your access is blocked");
        }
    }

}
```

测试

```java
package com.imooc.springcloud;

import com.imooc.springcloud.annotation.AccessLimit;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;

/**
 * Created by 半仙.
 */
@RestController
@Slf4j
public class Controller {

    @Autowired
    private AccessLimiter accessLimiter;

    @GetMapping("test")
    public String test() {
        accessLimiter.limitAccess("ratelimiter-test", 100);
        return "success";
    }

    // 提醒！ 注意配置扫包路径（com.imooc.springcloud路径不同）
    @GetMapping("test-annotation")
    @AccessLimit(limit = 1)
    public String testAnnotation() {
        return "success";
    }

}
```

